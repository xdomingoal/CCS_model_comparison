{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMhrT1Eqz5TQY8Zq4B3aW9T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ZSNYxhl_Nz5w"},"outputs":[],"source":["from keras.models import load_model, save_model\n","from keras.layers import Dense, Dropout, Flatten, Input, Concatenate, Embedding\n","from keras.layers import Conv1D, MaxPooling1D, Activation, BatchNormalization, Flatten\n","from keras.models import Model\n","import pandas as pd\n","import numpy as np\n","import h5py as h5\n","import keras\n","import logging\n","import random\n","\n","random.seed(1)\n","\n","data = pd.read_csv(\"drive/MyDrive/trainDeepCCS_editrow.csv\")\n","test = pd.read_csv(\"drive/MyDrive/testDeepCCS.csv\")\n","\n","#data = pd.read_csv(\"trainDeepCCS_editrow.csv\")\n","#test = pd.read_csv(\"testDeepCCS.csv\")\n","\n","\n","#Splitting SMILES from splitter.py\n","\n","class SMILESsplitter:\n","    def split(self, smiles):\n","        \"\"\"\n","        Split a single SMILES using chemical symbols and characters.\n","        Two letters chemical symbol that end with a 'c' might not be handled properly.\n","        Nitrogen, Sulfur and Oxygen can miss-handled if they are at the begining of an aromatic structure (ex: Coccc)\n","        As and Se will be splitted in two caracters if they are found in an aromatic structure.\n","        Only Co is seen in the current dataset and it is handled properly. TODO: better splitting.\n","        :param smiles: The SMILES to split\n","        :return: A list of chemical symbol/character ordered as\n","        \"\"\"\n","        splitted_smiles = []\n","        for j, k in enumerate(smiles):\n","            if j == 0:\n","                if k.isupper() and smiles[j + 1].islower() and smiles[j + 1] != \"c\":\n","                    splitted_smiles.append(k + smiles[j + 1])\n","                else:\n","                    splitted_smiles.append(k)\n","            elif j != 0 and j < len(smiles) - 1:\n","                if k.isupper() and smiles[j + 1].islower() and smiles[j + 1] != \"c\":\n","                    splitted_smiles.append(k + smiles[j + 1])\n","                elif k.islower() and smiles[j - 1].isupper() and k != \"c\":\n","                    pass\n","                else:\n","                    splitted_smiles.append(k)\n","            elif j == len(smiles) - 1:\n","                if k.islower() and smiles[j - 1].isupper() and k != \"c\":\n","                    pass\n","                else:\n","                    splitted_smiles.append(k)\n","        return splitted_smiles\n","\n","#SmilesToOneHotEncoder() modified\n","# Maximum Smile length that can be used with DeepCCS.\n","max_smiles_length = 250\n","MAX_SMILES_LENGTH = 250\n","# Accepter adducts by DeepCCS.\n","ADDUCTS_TO_KEEP = [\"M+H\", \"M+Na\", \"M-H\", \"M-2H\"]\n","\n","smiles_splitter = SMILESsplitter()\n","_max_length = max_smiles_length\n","\n","def _pad_smiles(smiles, padding_char=\" \"):\n","        _max_length = MAX_SMILES_LENGTH\n","        to_pad = int((_max_length - len(smiles)) / 2)\n","        s_padded_left = ([padding_char] * to_pad) + smiles\n","        return s_padded_left + ([padding_char] * (_max_length - len(s_padded_left)))\n","\n","\n","\n","##Encoding the train\n","#X = data[\"SMILES\"]\n","X = data[\"smiles\"]\n","splitted_smiles = [smiles_splitter.split(s) for s in X]\n","padded_splitted_smiles = [_pad_smiles(s) for s in splitted_smiles]\n","lengths = [len(s) for s in padded_splitted_smiles]\n","chars = [char for s in padded_splitted_smiles for char in s ]\n","number_of_element = len(padded_splitted_smiles)\n","\n","if len(set(lengths)) != 1:\n","  # print(lengths)\n","  raise ValueError(\"Items in X must be all of the same length\")\n","else:\n","  _max_length = lengths[0]\n","\n","converter = {}\n","for i,j in enumerate(set(chars)):\n","  converter[j] = i\n","\n","number_of_element = len(padded_splitted_smiles)\n","encoded_smiles = np.zeros((number_of_element, _max_length, len(converter)))\n","for i,smiles in enumerate(padded_splitted_smiles):\n","  for j, letter in enumerate(smiles):\n","    encoded_smiles[i,j, converter[letter]] = 1\n","\n","#One Hot Encoding the adducts\n","#adducts = data[\"Adducts\"]\n","adducts = data[\"Adduct\"]\n","converter = {}\n","for i, j in enumerate(set(adducts)):\n","  converter[j] = i\n","\n","number_of_element = adducts.shape[0]\n","encoded_adducts = np.zeros((number_of_element, len(converter)))\n","for i, adduct in enumerate(adducts):\n","  encoded_adducts[i, converter[adduct]] = 1\n","\n","\n","#Neural Network\n","Y_train = data[\"CCS_AVG\"]\n","smile_input_layer = Input(shape=encoded_smiles[1].shape, name = \"smiles\")\n","#smile_input_layer = Input(shape=(250, len(encoded_smiles)), name = \"smiles\")\n","#smile_input_layer = Input(shape=(250, encoded_smiles.shape[2]), name = \"smiles\")\n","conv = Conv1D(64, kernel_size = 4, activation = \"relu\", kernel_initializer = \"normal\")(smile_input_layer)\n","\n","previous = conv\n","for i in range(6):\n","  conv = Conv1D(64, kernel_size = 4, activation = \"relu\", kernel_initializer = \"normal\")(previous)\n","  if i == 5:\n","    pool = MaxPooling1D(pool_size = 2, strides = 2)(conv)\n","  else:\n","    pool = MaxPooling1D(pool_size = 2, strides = 1)(conv)\n","  previous = pool\n","\n","flat = Flatten()(previous)\n","#adduct_input_layer = Input(shape = (encoded_adducts.shape[1],),name = \"adduct\")\n","adduct_input_layer = Input(shape = encoded_adducts[1].shape,name = \"adduct\")\n","remix_layer = keras.layers.concatenate([flat, adduct_input_layer], axis = -1)\n","\n","previous = remix_layer\n","for i in range(2):\n","  dense_layer = Dense(384, activation = \"relu\", kernel_initializer = \"normal\")(previous)\n","  previous = dense_layer\n","\n","output = Dense(1, activation = \"linear\")(previous)\n","\n","opt = keras.optimizers.Adam(lr = 0.0001)\n","model = Model([smile_input_layer, adduct_input_layer], output)\n","model.compile(optimizer=opt, loss = \"mean_squared_error\")\n","deepccs_model = model.fit([encoded_smiles, encoded_adducts], Y_train, epochs = 25, batch_size = 2, validation_split = 0.1)"]},{"cell_type":"code","source":["adducts_test = test[\"Adduct\"]\n","converter = {}\n","for i, j in enumerate(set(adducts_test)):\n","  converter[j] = i\n","\n","number_of_element = adducts_test.shape[0]\n","\n","#Make a zero arrays with\n","encoded_adducts_test = np.zeros((number_of_element, len(converter)))\n","for i, adduct in enumerate(adducts_test):\n","  encoded_adducts_test[i, converter[adducts_test]] = 1\n","\n","encoded_adducts_test = np.zeros((number_of_element, len(converter)))\n","encoded_adducts_test"],"metadata":{"id":"LmD_Ub-Zt_dT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test = test[\"smiles\"]\n","splitted_smiles = [smiles_splitter.split(s) for s in X_test]\n","padded_splitted_smiles = [_pad_smiles(s) for s in splitted_smiles]\n","lengths = [len(s) for s in padded_splitted_smiles]\n","chars = [char for s in padded_splitted_smiles for char in s ]\n","\n","if len(set(lengths)) != 1:\n","  # print(lengths)\n","  raise ValueError(\"Items in X must be all of the same length\")\n","else:\n","  _max_length = lengths[0]\n","\n","converter = {}\n","for i,j in enumerate(set(chars)):\n","  converter[j] = i\n","\n","number_of_element = len(padded_splitted_smiles)\n","encoded_smiles = np.zeros((number_of_element, _max_length, len(converter)))\n","for i,smiles in enumerate(padded_splitted_smiles):\n","  for j, letter in enumerate(smiles):\n","    encoded_smiles[i,j, converter[letter]] = 1"],"metadata":{"id":"1nPMijQo9PrF"},"execution_count":null,"outputs":[]}]}